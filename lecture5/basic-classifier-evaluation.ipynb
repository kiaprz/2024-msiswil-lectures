{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "dfMachinePredictions = pl.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>footfall</th><th>tempMode</th><th>AQ</th><th>USS</th><th>CS</th><th>VOC</th><th>RP</th><th>IP</th><th>Temperature</th><th>fail</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>7</td><td>7</td><td>1</td><td>6</td><td>6</td><td>36</td><td>3</td><td>1</td><td>1</td></tr><tr><td>190</td><td>1</td><td>3</td><td>3</td><td>5</td><td>1</td><td>20</td><td>4</td><td>1</td><td>0</td></tr><tr><td>31</td><td>7</td><td>2</td><td>2</td><td>6</td><td>1</td><td>24</td><td>6</td><td>1</td><td>0</td></tr><tr><td>83</td><td>4</td><td>3</td><td>4</td><td>5</td><td>1</td><td>28</td><td>6</td><td>1</td><td>0</td></tr><tr><td>640</td><td>7</td><td>5</td><td>6</td><td>4</td><td>0</td><td>68</td><td>6</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌──────────┬──────────┬─────┬─────┬───┬─────┬─────┬─────────────┬──────┐\n",
       "│ footfall ┆ tempMode ┆ AQ  ┆ USS ┆ … ┆ RP  ┆ IP  ┆ Temperature ┆ fail │\n",
       "│ ---      ┆ ---      ┆ --- ┆ --- ┆   ┆ --- ┆ --- ┆ ---         ┆ ---  │\n",
       "│ i64      ┆ i64      ┆ i64 ┆ i64 ┆   ┆ i64 ┆ i64 ┆ i64         ┆ i64  │\n",
       "╞══════════╪══════════╪═════╪═════╪═══╪═════╪═════╪═════════════╪══════╡\n",
       "│ 0        ┆ 7        ┆ 7   ┆ 1   ┆ … ┆ 36  ┆ 3   ┆ 1           ┆ 1    │\n",
       "│ 190      ┆ 1        ┆ 3   ┆ 3   ┆ … ┆ 20  ┆ 4   ┆ 1           ┆ 0    │\n",
       "│ 31       ┆ 7        ┆ 2   ┆ 2   ┆ … ┆ 24  ┆ 6   ┆ 1           ┆ 0    │\n",
       "│ 83       ┆ 4        ┆ 3   ┆ 4   ┆ … ┆ 28  ┆ 6   ┆ 1           ┆ 0    │\n",
       "│ 640      ┆ 7        ┆ 5   ┆ 6   ┆ … ┆ 68  ┆ 6   ┆ 1           ┆ 0    │\n",
       "└──────────┴──────────┴─────┴─────┴───┴─────┴─────┴─────────────┴──────┘"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMachinePredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 10]\n",
      " [18 69]]\n",
      "Classifier used: MLPClassifier()\n",
      "Accuracy: 0.85\n",
      "Sensitivity (Recall for positive class): 0.79\n",
      "Specificity (Recall for negative class): 0.90\n",
      "ROC AUC: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Preprocess your data\n",
    "# Assuming the last column is the target variable\n",
    "X = dfMachinePredictions[:, :9]  # Features\n",
    "y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = MLPClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "print(f\"Classifier used: {clf}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Sensitivity (Recall for positive class): {sensitivity:.2f}\")\n",
    "print(f\"Specificity (Recall for negative class): {specificity:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy calculated from CM: 0.85\n",
      "Sensitivity calculated from CM: 0.79\n",
      "Specificity calculated from CM: 0.90\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = cm.ravel()\n",
    "\n",
    "sen = tn / (tn+fp)\n",
    "spe = tp / (tp+fn)\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(f\"Accuracy calculated from CM: {acc:.2f}\")\n",
    "print(f\"Sensitivity calculated from CM: {sen:.2f}\")\n",
    "print(f\"Specificity calculated from CM: {spe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 10]\n",
      " [15 72]]\n",
      "Classifier used: MLPClassifier()\n",
      "Accuracy: 0.87\n",
      "Sensitivity (Recall for positive class): 0.83\n",
      "Specificity (Recall for negative class): 0.90\n",
      "ROC AUC: 0.86\n",
      "[[81 21]\n",
      " [15 72]]\n",
      "Classifier used: DecisionTreeClassifier()\n",
      "Accuracy: 0.81\n",
      "Sensitivity (Recall for positive class): 0.83\n",
      "Specificity (Recall for negative class): 0.79\n",
      "ROC AUC: 0.81\n"
     ]
    }
   ],
   "source": [
    "def testClassifier(clf):\n",
    "    # Preprocess your data\n",
    "    # Assuming the last column is the target variable\n",
    "    X = dfMachinePredictions[:, :9]  # Features\n",
    "    y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree Classifier\n",
    "    #clf = MLPClassifier()\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "    print(f\"Classifier used: {clf}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Sensitivity (Recall for positive class): {sensitivity:.2f}\")\n",
    "    print(f\"Specificity (Recall for negative class): {specificity:.2f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n",
    "testClassifier(MLPClassifier())\n",
    "testClassifier(DecisionTreeClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used: MLPClassifier()\n",
      "Accuraccies: 0.8961612067995046\n",
      "Sensitivities (Recall for positive class): 0.8574488802336904\n",
      "Specificities (Recall for negative class): 0.9236855036855036\n",
      "ROC AUCs: 0.8905671919595971\n",
      "\n",
      "Classifier used: DecisionTreeClassifier()\n",
      "Accuraccies: 0.8432004953281549\n",
      "Sensitivities (Recall for positive class): 0.8065887698799091\n",
      "Specificities (Recall for negative class): 0.8694348894348896\n",
      "ROC AUCs: 0.8380118296573993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "def testClassifier(clf):\n",
    "    # Preprocess your data\n",
    "    # Assuming the last column is the target variable\n",
    "    X = dfMachinePredictions[:, :9]  # Features\n",
    "    y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "    accuracies = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    aucs = []\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Initialize the Decision Tree Classifier\n",
    "        #clf = MLPClassifier()\n",
    "\n",
    "        # Train the classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "        sensitivities.append(sensitivity)\n",
    "\n",
    "        specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "        specificities.append(specificity)\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Classifier used: {clf}\")\n",
    "    print(f\"Accuraccies: {np.mean(accuracies)}\")\n",
    "    print(f\"Sensitivities (Recall for positive class): {np.mean(sensitivities)}\")\n",
    "    print(f\"Specificities (Recall for negative class): {np.mean(specificities)}\")\n",
    "    print(f\"ROC AUCs: {np.mean(aucs)}\")\n",
    "\n",
    "\n",
    "testClassifier(MLPClassifier())\n",
    "print()\n",
    "testClassifier(DecisionTreeClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used: OneClassSVM(nu=0.7)\n",
      "Accuraccies: 0.6785714285714286\n",
      "Sensitivities (Recall for positive class): 0.7608142493638677\n",
      "Specificities (Recall for negative class): 0.38738738738738737\n",
      "ROC AUCs: 0.5741008183756275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "def mapOneClassResultToBinaryClassification(classificationResults):\n",
    "    # Create a copy of the array to avoid modifying the original\n",
    "    mapped_arr = np.copy(classificationResults)\n",
    "    # Map -1 to 1\n",
    "    mapped_arr[classificationResults == -1] = 1\n",
    "    # Map 1 to 0\n",
    "    mapped_arr[classificationResults == 1] = 0\n",
    "\n",
    "    return mapped_arr\n",
    "\n",
    "# Generate some training data\n",
    "#X_train = np.array([[0], [0.44], [0.45], [0.46], [1]])\n",
    "\n",
    "#normal dataset\n",
    "dfMachineNoFail = dfMachinePredictions.filter(pl.col(\"fail\")==0)\n",
    "\n",
    "X_normal = dfMachineNoFail[:, :9]\n",
    "y_normal = dfMachineNoFail[:, 9]\n",
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(X_normal, y_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = OneClassSVM(nu=0.7)\n",
    "clf.fit(X_train_normal)\n",
    "\n",
    "#normal test\n",
    "Y_normal_pred = mapOneClassResultToBinaryClassification(clf.predict(X_test_normal))\n",
    "\n",
    "#anomaly test\n",
    "dfMachineFail = dfMachinePredictions.filter(pl.col(\"fail\")==1)\n",
    "X_anomaly = dfMachineFail[:, :9]\n",
    "y_anomaly = dfMachineFail[:, 9]\n",
    "Y_anomaly_pred = mapOneClassResultToBinaryClassification(clf.predict(X_anomaly))\n",
    "\n",
    "y_test = np.concatenate((y_test_normal, y_anomaly))\n",
    "y_pred = np.concatenate((Y_normal_pred, Y_anomaly_pred)) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "print(f\"Classifier used: {clf}\")\n",
    "print(f\"Accuraccies: {accuracy}\")\n",
    "print(f\"Sensitivities (Recall for positive class): {sensitivity}\")\n",
    "print(f\"Specificities (Recall for negative class): {specificity}\")\n",
    "print(f\"ROC AUCs: {roc_auc}\")\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "# Predict on the training data\n",
    "#predictions = clf.predict(X_train)\n",
    "#print(predictions)  # Output: array([-1,  1,  1,  1, -1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
