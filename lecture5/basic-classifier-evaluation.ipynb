{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "dfMachinePredictions = pl.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>footfall</th><th>tempMode</th><th>AQ</th><th>USS</th><th>CS</th><th>VOC</th><th>RP</th><th>IP</th><th>Temperature</th><th>fail</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>7</td><td>7</td><td>1</td><td>6</td><td>6</td><td>36</td><td>3</td><td>1</td><td>1</td></tr><tr><td>190</td><td>1</td><td>3</td><td>3</td><td>5</td><td>1</td><td>20</td><td>4</td><td>1</td><td>0</td></tr><tr><td>31</td><td>7</td><td>2</td><td>2</td><td>6</td><td>1</td><td>24</td><td>6</td><td>1</td><td>0</td></tr><tr><td>83</td><td>4</td><td>3</td><td>4</td><td>5</td><td>1</td><td>28</td><td>6</td><td>1</td><td>0</td></tr><tr><td>640</td><td>7</td><td>5</td><td>6</td><td>4</td><td>0</td><td>68</td><td>6</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌──────────┬──────────┬─────┬─────┬───┬─────┬─────┬─────────────┬──────┐\n",
       "│ footfall ┆ tempMode ┆ AQ  ┆ USS ┆ … ┆ RP  ┆ IP  ┆ Temperature ┆ fail │\n",
       "│ ---      ┆ ---      ┆ --- ┆ --- ┆   ┆ --- ┆ --- ┆ ---         ┆ ---  │\n",
       "│ i64      ┆ i64      ┆ i64 ┆ i64 ┆   ┆ i64 ┆ i64 ┆ i64         ┆ i64  │\n",
       "╞══════════╪══════════╪═════╪═════╪═══╪═════╪═════╪═════════════╪══════╡\n",
       "│ 0        ┆ 7        ┆ 7   ┆ 1   ┆ … ┆ 36  ┆ 3   ┆ 1           ┆ 1    │\n",
       "│ 190      ┆ 1        ┆ 3   ┆ 3   ┆ … ┆ 20  ┆ 4   ┆ 1           ┆ 0    │\n",
       "│ 31       ┆ 7        ┆ 2   ┆ 2   ┆ … ┆ 24  ┆ 6   ┆ 1           ┆ 0    │\n",
       "│ 83       ┆ 4        ┆ 3   ┆ 4   ┆ … ┆ 28  ┆ 6   ┆ 1           ┆ 0    │\n",
       "│ 640      ┆ 7        ┆ 5   ┆ 6   ┆ … ┆ 68  ┆ 6   ┆ 1           ┆ 0    │\n",
       "└──────────┴──────────┴─────┴─────┴───┴─────┴─────┴─────────────┴──────┘"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMachinePredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85 17]\n",
      " [ 9 78]]\n",
      "Classifier used: MLPClassifier()\n",
      "Accuracy: 0.86\n",
      "Sensitivity (Recall for positive class): 0.90\n",
      "Specificity (Recall for negative class): 0.83\n",
      "ROC AUC: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Preprocess your data\n",
    "# Assuming the last column is the target variable\n",
    "X = dfMachinePredictions[:, :9]  # Features\n",
    "y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = MLPClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "print(f\"Classifier used: {clf}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Sensitivity (Recall for positive class): {sensitivity:.2f}\")\n",
    "print(f\"Specificity (Recall for negative class): {specificity:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy calculated from CM: 0.86\n",
      "Sensitivity calculated from CM: 0.90\n",
      "Specificity calculated from CM: 0.83\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = cm.ravel()\n",
    "\n",
    "sen = tn / (tn+fp)\n",
    "spe = tp / (tp+fn)\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(f\"Accuracy calculated from CM: {acc:.2f}\")\n",
    "print(f\"Sensitivity calculated from CM: {sen:.2f}\")\n",
    "print(f\"Specificity calculated from CM: {spe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 15]\n",
      " [10 77]]\n",
      "Classifier used: MLPClassifier()\n",
      "Accuracy: 0.87\n",
      "Sensitivity (Recall for positive class): 0.89\n",
      "Specificity (Recall for negative class): 0.85\n",
      "ROC AUC: 0.87\n",
      "[[82 20]\n",
      " [17 70]]\n",
      "Classifier used: DecisionTreeClassifier()\n",
      "Accuracy: 0.80\n",
      "Sensitivity (Recall for positive class): 0.80\n",
      "Specificity (Recall for negative class): 0.80\n",
      "ROC AUC: 0.80\n"
     ]
    }
   ],
   "source": [
    "def testClassifier(clf):\n",
    "    # Preprocess your data\n",
    "    # Assuming the last column is the target variable\n",
    "    X = dfMachinePredictions[:, :9]  # Features\n",
    "    y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree Classifier\n",
    "    #clf = MLPClassifier()\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "    specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "    print(f\"Classifier used: {clf}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Sensitivity (Recall for positive class): {sensitivity:.2f}\")\n",
    "    print(f\"Specificity (Recall for negative class): {specificity:.2f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n",
    "testClassifier(MLPClassifier())\n",
    "testClassifier(DecisionTreeClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier used: MLPClassifier()\n",
      "Accuraccies: 0.8993245525160418\n",
      "Sensitivities (Recall for positive class): 0.8549496916585524\n",
      "Specificities (Recall for negative class): 0.9310728910728912\n",
      "ROC AUCs: 0.8930112913657217\n",
      "\n",
      "Classifier used: DecisionTreeClassifier()\n",
      "Accuraccies: 0.8475008443093548\n",
      "Sensitivities (Recall for positive class): 0.8348263550795197\n",
      "Specificities (Recall for negative class): 0.8565765765765766\n",
      "ROC AUCs: 0.8457014658280482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "def testClassifier(clf):\n",
    "    # Preprocess your data\n",
    "    # Assuming the last column is the target variable\n",
    "    X = dfMachinePredictions[:, :9]  # Features\n",
    "    y = dfMachinePredictions[:, 9]   # Target\n",
    "\n",
    "    accuracies = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    aucs = []\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Initialize the Decision Tree Classifier\n",
    "        #clf = MLPClassifier()\n",
    "\n",
    "        # Train the classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        #print(cm)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "        sensitivities.append(sensitivity)\n",
    "\n",
    "        specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "        specificities.append(specificity)\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Classifier used: {clf}\")\n",
    "    print(f\"Accuraccies: {np.mean(accuracies)}\")\n",
    "    print(f\"Sensitivities (Recall for positive class): {np.mean(sensitivities)}\")\n",
    "    print(f\"Specificities (Recall for negative class): {np.mean(specificities)}\")\n",
    "    print(f\"ROC AUCs: {np.mean(aucs)}\")\n",
    "\n",
    "\n",
    "testClassifier(MLPClassifier())\n",
    "print()\n",
    "testClassifier(DecisionTreeClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [551, 944]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m X_normal \u001b[38;5;241m=\u001b[39m dfMachineNoFail[:, :\u001b[38;5;241m9\u001b[39m]\n\u001b[1;32m     22\u001b[0m y_normal \u001b[38;5;241m=\u001b[39m dfMachineNoFail[:, \u001b[38;5;241m9\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m X_train_normal, X_test_normal, y_train_normal, y_test_normal \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m clf \u001b[38;5;241m=\u001b[39m OneClassSVM(nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     26\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_normal)\n",
      "File \u001b[0;32m~/prz/msi_swil_2024/code/ml/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/prz/msi_swil_2024/code/ml/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2782\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2786\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2787\u001b[0m )\n",
      "File \u001b[0;32m~/prz/msi_swil_2024/code/ml/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/prz/msi_swil_2024/code/ml/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [551, 944]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "def mapOneClassResultToBinaryClassification(classificationResults):\n",
    "    # Create a copy of the array to avoid modifying the original\n",
    "    mapped_arr = np.copy(classificationResults)\n",
    "    # Map -1 to 1\n",
    "    mapped_arr[classificationResults == -1] = 1\n",
    "    # Map 1 to 0\n",
    "    mapped_arr[classificationResults == 1] = 0\n",
    "\n",
    "    return mapped_arr\n",
    "\n",
    "# Generate some training data\n",
    "#X_train = np.array([[0], [0.44], [0.45], [0.46], [1]])\n",
    "\n",
    "#normal dataset\n",
    "dfMachineNoFail = dfMachinePredictions.filter(pl.col(\"fail\")==0)\n",
    "\n",
    "X_normal = dfMachineNoFail[:, :9]\n",
    "y_normal = dfMachineNoFail[:, 9]\n",
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(X_normal, y_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = OneClassSVM(nu=0.7)\n",
    "clf.fit(X_train_normal)\n",
    "\n",
    "#normal test\n",
    "Y_normal_pred = mapOneClassResultToBinaryClassification(clf.predict(X_test_normal))\n",
    "\n",
    "#anomaly test\n",
    "dfMachineFail = dfMachinePredictions.filter(pl.col(\"fail\")==1)\n",
    "X_anomaly = dfMachineFail[:, :9]\n",
    "y_anomaly = dfMachineFail[:, 9]\n",
    "Y_anomaly_pred = mapOneClassResultToBinaryClassification(clf.predict(X_anomaly))\n",
    "\n",
    "y_test = np.concatenate((y_test_normal, y_anomaly))\n",
    "y_pred = np.concatenate((Y_normal_pred, Y_anomaly_pred)) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred, pos_label=1)  # Sensitivity (Recall) for positive class\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)  # Recall for the negative class = Specificity\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # AUC requires predicted probabilities\n",
    "\n",
    "print(f\"Classifier used: {clf}\")\n",
    "print(f\"Accuraccies: {accuracy}\")\n",
    "print(f\"Sensitivities (Recall for positive class): {sensitivity}\")\n",
    "print(f\"Specificities (Recall for negative class): {specificity}\")\n",
    "print(f\"ROC AUCs: {roc_auc}\")\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "# Predict on the training data\n",
    "#predictions = clf.predict(X_train)\n",
    "#print(predictions)  # Output: array([-1,  1,  1,  1, -1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
